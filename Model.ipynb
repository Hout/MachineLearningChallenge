{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the libs and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199523, 398)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n\\nimport pandas as pd\\n\\nX_train = pd.read_csv(\\\"x_train.csv\\\", index_col=\\\"Index\\\")\\nX_train.shape\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n\\nimport pandas as pd\\n\\nX_train = pd.read_csv(\\\"x_train.csv\\\", index_col=\\\"Index\\\")\\nX_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"x_train.csv\", index_col=\"Index\")\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199523,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"y_train = pd.read_csv(\\\"y_train.csv\\\", index_col=\\\"Index\\\", squeeze=True)\\ny_train.shape\";\n",
       "                var nbb_formatted_code = \"y_train = pd.read_csv(\\\"y_train.csv\\\", index_col=\\\"Index\\\", squeeze=True)\\ny_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = pd.read_csv(\"y_train.csv\", index_col=\"Index\", squeeze=True)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99762, 398)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"X_test = pd.read_csv(\\\"x_test.csv\\\", index_col=\\\"Index\\\")\\nX_test.shape\";\n",
       "                var nbb_formatted_code = \"X_test = pd.read_csv(\\\"x_test.csv\\\", index_col=\\\"Index\\\")\\nX_test.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"x_test.csv\", index_col=\"Index\")\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a parameter search engine to find the optimal settings.\n",
    "Per classifier select the parameter values.\n",
    "I also reduce dimensions with PCA to speed up processing.\n",
    "\n",
    "Processing takes a looooong time so I included the results in a markup below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhxEcezfdvbW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "classifiers = {\n",
    "    \"SDG\": (\n",
    "        SGDClassifier(),\n",
    "        {\n",
    "            \"loss\": [\"hinge\", \"log\", \"modified_huber\", \"perceptron\"],\n",
    "            \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "            \"n_jobs\": [-1],\n",
    "        },\n",
    "    ),\n",
    "    \"Ridge\": (\n",
    "        RidgeClassifier(),\n",
    "        {\n",
    "            \"alpha\": [0.0001, 0.5, 1.0],\n",
    "            \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"],\n",
    "        },\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(),\n",
    "        {\n",
    "            \"n_estimators\": [30, 100, 300],\n",
    "            \"min_samples_split\": [2 ** i for i in range(1, 4)],\n",
    "            \"max_features\": [\"sqrt\", \"log2\"],\n",
    "            \"max_depth\": [None] + [2 ** i for i in range(1, 7)],\n",
    "            \"n_jobs\": [-1],\n",
    "        },\n",
    "    ),\n",
    "    \"Extra Trees\": (\n",
    "        ExtraTreesClassifier(),\n",
    "        {\n",
    "            \"n_estimators\": [30, 100, 300],\n",
    "            \"min_samples_split\": [2 ** i for i in range(1, 4)],\n",
    "            \"max_features\": [\"sqrt\", \"log2\"],\n",
    "            \"max_depth\": [None] + [2 ** i for i in range(1, 7)],\n",
    "            \"n_jobs\": [-1],\n",
    "        },\n",
    "    ),\n",
    "    \"Nearest Neighbours\": (\n",
    "        KNeighborsClassifier(),\n",
    "        {\n",
    "            \"n_neighbors\": [3, 5, 7],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"algorithm\": [\"ball_tree\", \"kd_tree\"], #, \"auto\", \"brute\"]\n",
    "            \"leaf_size\": [10, 30, 50],\n",
    "            \"p\": [1, 2],\n",
    "            \"n_jobs\": [-1],\n",
    "        },\n",
    "    ),\n",
    "}\n",
    "\n",
    "X_train_pca = {}\n",
    "for n_components in [2**i for i in range(1, 8)]:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca[n_components] = pca.fit_transform(X_train)\n",
    "\n",
    "for n_components, X in X_train_pca.items():\n",
    "    for name, (classifier, param_grid) in classifiers.items():\n",
    "    #     search = GridSearchCV(pipeline, pca_param_grid, n_jobs=-1)\n",
    "        search = RandomizedSearchCV(classifier, param_grid, n_iter=10)\n",
    "        search.fit(X, y_train)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"Dimensions={n_components}\")\n",
    "        print(f\"Best parameter (CV score={search.best_score_:.4f}):\")\n",
    "        print(search.best_params_)\n",
    "        print(search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "```\n",
    "SDG:\n",
    "Dimensions=2\n",
    "Best parameter (CV score=0.9342):\n",
    "{'penalty': 'l1', 'n_jobs': -1, 'loss': 'hinge'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l1',\n",
    "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=2\n",
    "Best parameter (CV score=0.9401):\n",
    "{'solver': 'cholesky', 'alpha': 0.0001}\n",
    "RidgeClassifier(alpha=0.0001, class_weight=None, copy_X=True,\n",
    "                fit_intercept=True, max_iter=None, normalize=False,\n",
    "                random_state=None, solver='cholesky', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=2\n",
    "Best parameter (CV score=0.9468):\n",
    "{'n_jobs': -1, 'n_estimators': 100, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 8}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=8, max_features='sqrt',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=2\n",
    "Best parameter (CV score=0.9474):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'log2', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='log2',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=4,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=2\n",
    "Best parameter (CV score=0.9448):\n",
    "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 10, 'algorithm': 'ball_tree'}\n",
    "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='uniform')\n",
    "SDG:\n",
    "Dimensions=4\n",
    "Best parameter (CV score=0.9292):\n",
    "{'penalty': 'elasticnet', 'n_jobs': -1, 'loss': 'perceptron'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='perceptron',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1,\n",
    "              penalty='elasticnet', power_t=0.5, random_state=None,\n",
    "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
    "              warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=4\n",
    "Best parameter (CV score=0.9400):\n",
    "{'solver': 'saga', 'alpha': 1.0}\n",
    "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='saga', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=4\n",
    "Best parameter (CV score=0.9485):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 8}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=8, max_features='sqrt',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=4\n",
    "Best parameter (CV score=0.9491):\n",
    "{'n_jobs': -1, 'n_estimators': 100, 'min_samples_split': 4, 'max_features': 'log2', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='log2',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=4,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=4\n",
    "Best parameter (CV score=0.9460):\n",
    "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 30, 'algorithm': 'kd_tree'}\n",
    "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='uniform')\n",
    "SDG:\n",
    "Dimensions=8\n",
    "Best parameter (CV score=0.9253):\n",
    "{'penalty': 'l1', 'n_jobs': -1, 'loss': 'perceptron'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='perceptron',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l1',\n",
    "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=8\n",
    "Best parameter (CV score=0.9405):\n",
    "{'solver': 'auto', 'alpha': 0.5}\n",
    "RidgeClassifier(alpha=0.5, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='auto', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=8\n",
    "Best parameter (CV score=0.9514):\n",
    "{'n_jobs': -1, 'n_estimators': 100, 'min_samples_split': 4, 'max_features': 'log2', 'max_depth': 16}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=16, max_features='log2',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=8\n",
    "Best parameter (CV score=0.9508):\n",
    "{'n_jobs': -1, 'n_estimators': 100, 'min_samples_split': 8, 'max_features': 'sqrt', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=8,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=8\n",
    "Best parameter (CV score=0.9474):\n",
    "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 30, 'algorithm': 'ball_tree'}\n",
    "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='uniform')\n",
    "SDG:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9241):\n",
    "{'penalty': 'l2', 'n_jobs': -1, 'loss': 'modified_huber'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
    "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "Ridge:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9408):\n",
    "{'solver': 'svd', 'alpha': 1.0}\n",
    "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None, solver='svd',\n",
    "                tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9535):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 16}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=16, max_features='log2',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9531):\n",
    "{'n_jobs': -1, 'n_estimators': 100, 'min_samples_split': 8, 'max_features': 'sqrt', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=8,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9484):\n",
    "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 50, 'algorithm': 'kd_tree'}\n",
    "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='uniform')\n",
    "SDG:\n",
    "Dimensions=32\n",
    "Best parameter (CV score=0.9292):\n",
    "{'penalty': 'l1', 'n_jobs': -1, 'loss': 'log'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
    "              n_iter_no_change=5, n_jobs=-1, penalty='l1', power_t=0.5,\n",
    "              random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=32\n",
    "Best parameter (CV score=0.9418):\n",
    "{'solver': 'auto', 'alpha': 0.5}\n",
    "RidgeClassifier(alpha=0.5, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='auto', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=32\n",
    "Best parameter (CV score=0.9536):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'log2', 'max_depth': 64}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=64, max_features='log2',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=32\n",
    "Best parameter (CV score=0.9524):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'sqrt', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=4,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=32\n",
    "Best parameter (CV score=0.9487):\n",
    "{'weights': 'uniform', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 10, 'algorithm': 'ball_tree'}\n",
    "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='uniform')\n",
    "SDG:\n",
    "Dimensions=64\n",
    "Best parameter (CV score=0.9276):\n",
    "{'penalty': 'elasticnet', 'n_jobs': -1, 'loss': 'modified_huber'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1,\n",
    "              penalty='elasticnet', power_t=0.5, random_state=None,\n",
    "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
    "              warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=64\n",
    "Best parameter (CV score=0.9424):\n",
    "{'solver': 'auto', 'alpha': 0.0001}\n",
    "RidgeClassifier(alpha=0.0001, class_weight=None, copy_X=True,\n",
    "                fit_intercept=True, max_iter=None, normalize=False,\n",
    "                random_state=None, solver='auto', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=64\n",
    "Best parameter (CV score=0.9539):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'sqrt', 'max_depth': None}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=64\n",
    "Best parameter (CV score=0.9516):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 8, 'max_features': 'sqrt', 'max_depth': 32}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=32, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=8,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=64\n",
    "Best parameter (CV score=0.9486):\n",
    "{'weights': 'distance', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 10, 'algorithm': 'kd_tree'}\n",
    "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='distance')\n",
    "SDG:\n",
    "Dimensions=128\n",
    "Best parameter (CV score=0.9239):\n",
    "{'penalty': 'elasticnet', 'n_jobs': -1, 'loss': 'perceptron'}\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='perceptron',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=-1,\n",
    "              penalty='elasticnet', power_t=0.5, random_state=None,\n",
    "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
    "              warm_start=False)\n",
    "Ridge:\n",
    "Dimensions=128\n",
    "Best parameter (CV score=0.9444):\n",
    "{'solver': 'auto', 'alpha': 0.0001}\n",
    "RidgeClassifier(alpha=0.0001, class_weight=None, copy_X=True,\n",
    "                fit_intercept=True, max_iter=None, normalize=False,\n",
    "                random_state=None, solver='auto', tol=0.001)\n",
    "Random Forest:\n",
    "Dimensions=128\n",
    "Best parameter (CV score=0.9532):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'sqrt', 'max_depth': 64}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=64, max_features='sqrt',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "Extra Trees:\n",
    "Dimensions=128\n",
    "Best parameter (CV score=0.9493):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 4, 'max_features': 'sqrt', 'max_depth': 64}\n",
    "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='gini', max_depth=64, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=4,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
    "                     oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "Nearest Neighbours:\n",
    "Dimensions=128\n",
    "Best parameter (CV score=0.9491):\n",
    "{'weights': 'distance', 'p': 1, 'n_neighbors': 7, 'n_jobs': -1, 'leaf_size': 10, 'algorithm': 'ball_tree'}\n",
    "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=7, p=1,\n",
    "                     weights='distance')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best classifier:\n",
    "```\n",
    "Random Forest:\n",
    "Dimensions=16\n",
    "Best parameter (CV score=0.9535):\n",
    "{'n_jobs': -1, 'n_estimators': 300, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 16}\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=16, max_features='log2',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "```\n",
    "\n",
    "So let us do that and predict y_test."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
